{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Su40vWdD6VR9"
      },
      "source": [
        "# Automatic Image Captioning\n",
        "\n",
        "--------------------------------\n",
        "## Install additional libraries"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ulbAQZZOtjVt"
      },
      "outputs": [],
      "source": [
        "from IPython.display import clear_output\n",
        "!pip install -q rouge-score\n",
        "clear_output()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "G_MmlcPP6YlR",
        "outputId": "5ea047b5-0557-4794-d75b-fe0dac19450a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SWDsxLe56VR_",
        "outputId": "9cc1bfd1-de5b-45d7-db18-6813c259a5f8"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: opencv-python-headless in /usr/local/lib/python3.10/dist-packages (4.9.0.80)\n",
            "Requirement already satisfied: numpy>=1.21.2 in /usr/local/lib/python3.10/dist-packages (from opencv-python-headless) (1.25.2)\n"
          ]
        }
      ],
      "source": [
        "!pip install opencv-python-headless\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zbgWjHNl6VSA",
        "outputId": "c557297d-0925-4532-adbb-3020611b0e63"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: torchtext in /usr/local/lib/python3.10/dist-packages (0.17.1)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from torchtext) (4.66.2)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from torchtext) (2.31.0)\n",
            "Requirement already satisfied: torch==2.2.1 in /usr/local/lib/python3.10/dist-packages (from torchtext) (2.2.1+cu121)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from torchtext) (1.25.2)\n",
            "Requirement already satisfied: torchdata==0.7.1 in /usr/local/lib/python3.10/dist-packages (from torchtext) (0.7.1)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch==2.2.1->torchtext) (3.13.4)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from torch==2.2.1->torchtext) (4.11.0)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch==2.2.1->torchtext) (1.12)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch==2.2.1->torchtext) (3.3)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch==2.2.1->torchtext) (3.1.3)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch==2.2.1->torchtext) (2023.6.0)\n",
            "Collecting nvidia-cuda-nvrtc-cu12==12.1.105 (from torch==2.2.1->torchtext)\n",
            "  Using cached nvidia_cuda_nvrtc_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (23.7 MB)\n",
            "Collecting nvidia-cuda-runtime-cu12==12.1.105 (from torch==2.2.1->torchtext)\n",
            "  Using cached nvidia_cuda_runtime_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (823 kB)\n",
            "Collecting nvidia-cuda-cupti-cu12==12.1.105 (from torch==2.2.1->torchtext)\n",
            "  Using cached nvidia_cuda_cupti_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (14.1 MB)\n",
            "Collecting nvidia-cudnn-cu12==8.9.2.26 (from torch==2.2.1->torchtext)\n",
            "  Using cached nvidia_cudnn_cu12-8.9.2.26-py3-none-manylinux1_x86_64.whl (731.7 MB)\n",
            "Collecting nvidia-cublas-cu12==12.1.3.1 (from torch==2.2.1->torchtext)\n",
            "  Using cached nvidia_cublas_cu12-12.1.3.1-py3-none-manylinux1_x86_64.whl (410.6 MB)\n",
            "Collecting nvidia-cufft-cu12==11.0.2.54 (from torch==2.2.1->torchtext)\n",
            "  Using cached nvidia_cufft_cu12-11.0.2.54-py3-none-manylinux1_x86_64.whl (121.6 MB)\n",
            "Collecting nvidia-curand-cu12==10.3.2.106 (from torch==2.2.1->torchtext)\n",
            "  Using cached nvidia_curand_cu12-10.3.2.106-py3-none-manylinux1_x86_64.whl (56.5 MB)\n",
            "Collecting nvidia-cusolver-cu12==11.4.5.107 (from torch==2.2.1->torchtext)\n",
            "  Using cached nvidia_cusolver_cu12-11.4.5.107-py3-none-manylinux1_x86_64.whl (124.2 MB)\n",
            "Collecting nvidia-cusparse-cu12==12.1.0.106 (from torch==2.2.1->torchtext)\n",
            "  Using cached nvidia_cusparse_cu12-12.1.0.106-py3-none-manylinux1_x86_64.whl (196.0 MB)\n",
            "Collecting nvidia-nccl-cu12==2.19.3 (from torch==2.2.1->torchtext)\n",
            "  Using cached nvidia_nccl_cu12-2.19.3-py3-none-manylinux1_x86_64.whl (166.0 MB)\n",
            "Collecting nvidia-nvtx-cu12==12.1.105 (from torch==2.2.1->torchtext)\n",
            "  Using cached nvidia_nvtx_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (99 kB)\n",
            "Requirement already satisfied: triton==2.2.0 in /usr/local/lib/python3.10/dist-packages (from torch==2.2.1->torchtext) (2.2.0)\n",
            "Requirement already satisfied: urllib3>=1.25 in /usr/local/lib/python3.10/dist-packages (from torchdata==0.7.1->torchtext) (2.0.7)\n",
            "Collecting nvidia-nvjitlink-cu12 (from nvidia-cusolver-cu12==11.4.5.107->torch==2.2.1->torchtext)\n",
            "  Using cached nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (21.1 MB)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->torchtext) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->torchtext) (3.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->torchtext) (2024.2.2)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch==2.2.1->torchtext) (2.1.5)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch==2.2.1->torchtext) (1.3.0)\n",
            "Installing collected packages: nvidia-nvtx-cu12, nvidia-nvjitlink-cu12, nvidia-nccl-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, nvidia-cusparse-cu12, nvidia-cudnn-cu12, nvidia-cusolver-cu12\n",
            "Successfully installed nvidia-cublas-cu12-12.1.3.1 nvidia-cuda-cupti-cu12-12.1.105 nvidia-cuda-nvrtc-cu12-12.1.105 nvidia-cuda-runtime-cu12-12.1.105 nvidia-cudnn-cu12-8.9.2.26 nvidia-cufft-cu12-11.0.2.54 nvidia-curand-cu12-10.3.2.106 nvidia-cusolver-cu12-11.4.5.107 nvidia-cusparse-cu12-12.1.0.106 nvidia-nccl-cu12-2.19.3 nvidia-nvjitlink-cu12-12.4.127 nvidia-nvtx-cu12-12.1.105\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (2.2.1+cu121)\n",
            "Requirement already satisfied: torchvision in /usr/local/lib/python3.10/dist-packages (0.17.1+cu121)\n",
            "Requirement already satisfied: torchaudio in /usr/local/lib/python3.10/dist-packages (2.2.1+cu121)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch) (3.13.4)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from torch) (4.11.0)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch) (1.12)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch) (3.3)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch) (3.1.3)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch) (2023.6.0)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==8.9.2.26 in /usr/local/lib/python3.10/dist-packages (from torch) (8.9.2.26)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.1.3.1 in /usr/local/lib/python3.10/dist-packages (from torch) (12.1.3.1)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.0.2.54 in /usr/local/lib/python3.10/dist-packages (from torch) (11.0.2.54)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.2.106 in /usr/local/lib/python3.10/dist-packages (from torch) (10.3.2.106)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.4.5.107 in /usr/local/lib/python3.10/dist-packages (from torch) (11.4.5.107)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.1.0.106 in /usr/local/lib/python3.10/dist-packages (from torch) (12.1.0.106)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.19.3 in /usr/local/lib/python3.10/dist-packages (from torch) (2.19.3)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch) (12.1.105)\n",
            "Requirement already satisfied: triton==2.2.0 in /usr/local/lib/python3.10/dist-packages (from torch) (2.2.0)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12 in /usr/local/lib/python3.10/dist-packages (from nvidia-cusolver-cu12==11.4.5.107->torch) (12.4.127)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from torchvision) (1.25.2)\n",
            "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.10/dist-packages (from torchvision) (9.4.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch) (2.1.5)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch) (1.3.0)\n"
          ]
        }
      ],
      "source": [
        "!pip install torchtext\n",
        "!pip install torch torchvision torchaudio\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iOhet7jB1w-f",
        "outputId": "20ac1908-22d6-4140-a68c-65de0eb6cdbd"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package omw-1.4 to /root/nltk_data...\n",
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "execution_count": 8,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "from PIL import Image\n",
        "import os\n",
        "from os.path import exists\n",
        "import re\n",
        "import string\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.autograd import Variable\n",
        "import cv2\n",
        "import torchvision\n",
        "from torch.utils.data import DataLoader, random_split\n",
        "from torchtext.data.metrics import bleu_score\n",
        "from rouge_score import rouge_scorer\n",
        "from collections import Counter\n",
        "from tqdm import tqdm\n",
        "import pickle\n",
        "import nltk\n",
        "from nltk.translate.bleu_score import sentence_bleu\n",
        "\n",
        "import warnings\n",
        "warnings.filterwarnings(action='ignore')\n",
        "\n",
        "nltk.download('omw-1.4')\n",
        "nltk.download('wordnet')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LCcuMg2I6VSA"
      },
      "source": [
        "## Check for GPU"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "O8ZEW4XI1w-i",
        "outputId": "55cbccd0-ce21-45cf-e9ed-243edf1a9013"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "cuda:0\n"
          ]
        }
      ],
      "source": [
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(device)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "haNmOBir6VSA"
      },
      "source": [
        "## Load captions from dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 223
        },
        "id": "ObP-PQtD1w-m",
        "outputId": "257a8635-f17a-494d-cb02-2133916a8bc0"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "(40455, 2)\n"
          ]
        },
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "summary": "{\n  \"name\": \"df\",\n  \"rows\": 40455,\n  \"fields\": [\n    {\n      \"column\": \"image_name\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 8091,\n        \"samples\": [\n          \"3139895886_5a6d495b13.jpg\",\n          \"3133825703_359a0c414d.jpg\",\n          \"244910177_7c4ec3f65b.jpg\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"comment\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 40201,\n        \"samples\": [\n          \"A girl plays T-ball .\",\n          \"A woman in riding attire rides a jumping horse .\",\n          \"A brown dog wearing a pink shirt is followed by a brown dog wearing a yellow shirt .\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}",
              "type": "dataframe",
              "variable_name": "df"
            },
            "text/html": [
              "\n",
              "  <div id=\"df-1f32e452-931a-4c3e-8c06-815fd5e6119f\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>image_name</th>\n",
              "      <th>comment</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1000268201_693b08cb0e.jpg</td>\n",
              "      <td>A child in a pink dress is climbing up a set o...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1000268201_693b08cb0e.jpg</td>\n",
              "      <td>A girl going into a wooden building .</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>1000268201_693b08cb0e.jpg</td>\n",
              "      <td>A little girl climbing into a wooden playhouse .</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>1000268201_693b08cb0e.jpg</td>\n",
              "      <td>A little girl climbing the stairs to her playh...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>1000268201_693b08cb0e.jpg</td>\n",
              "      <td>A little girl in a pink dress going into a woo...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-1f32e452-931a-4c3e-8c06-815fd5e6119f')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-1f32e452-931a-4c3e-8c06-815fd5e6119f button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-1f32e452-931a-4c3e-8c06-815fd5e6119f');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-4a92db98-92c2-4d73-af7a-9248179a5d61\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-4a92db98-92c2-4d73-af7a-9248179a5d61')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-4a92db98-92c2-4d73-af7a-9248179a5d61 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "text/plain": [
              "                  image_name  \\\n",
              "0  1000268201_693b08cb0e.jpg   \n",
              "1  1000268201_693b08cb0e.jpg   \n",
              "2  1000268201_693b08cb0e.jpg   \n",
              "3  1000268201_693b08cb0e.jpg   \n",
              "4  1000268201_693b08cb0e.jpg   \n",
              "\n",
              "                                             comment  \n",
              "0  A child in a pink dress is climbing up a set o...  \n",
              "1              A girl going into a wooden building .  \n",
              "2   A little girl climbing into a wooden playhouse .  \n",
              "3  A little girl climbing the stairs to her playh...  \n",
              "4  A little girl in a pink dress going into a woo...  "
            ]
          },
          "execution_count": 10,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df = pd.read_csv('/content/drive/MyDrive/archive (4)/captions.txt', delimiter=',', dtype={'caption': str})\n",
        "df.columns = ['image_name','comment']\n",
        "print(df.shape)\n",
        "df.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ngj16eWq6VSA"
      },
      "source": [
        "## Preprocessing of captions\n",
        "\n",
        "### Text cleaning"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "x-DMsJvp1w-p",
        "outputId": "d8ee2c7a-9031-4d18-a218-80bf3e13fe07"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 40455/40455 [00:14<00:00, 2730.90it/s]\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "0        a child in a pink dress is climbing up a set o...\n",
              "1                     a girl going into a wooden building \n",
              "2          a little girl climbing into a wooden playhouse \n",
              "3        a little girl climbing the stairs to her playh...\n",
              "4        a little girl in a pink dress going into a woo...\n",
              "                               ...                        \n",
              "40450             a man in a pink shirt climbs a rock face\n",
              "40451              a man is rock climbing high in the air \n",
              "40452    a person in a red shirt climbing up a rock fac...\n",
              "40453                       a rock climber in a red shirt \n",
              "40454    a rock climber practices on a rock climbing wall \n",
              "Name: comment, Length: 40455, dtype: object"
            ]
          },
          "execution_count": 11,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "#remember: not removing stopwords, as we are learning entire sentence. We want to learn and predict stopwords too!\n",
        "#also, can't lemmatize words as we are learning to generate sentences.\n",
        "\n",
        "regex = re.compile('[%s]' % re.escape(string.punctuation))\n",
        "def clean_text(row):\n",
        "    row = str(row).strip()\n",
        "    row = row.lower()\n",
        "    return regex.sub(\"\", row)\n",
        "\n",
        "with tqdm(total=len(df['comment'].values)) as progress_bar:\n",
        "    for i, caption in enumerate(df['comment'].values):\n",
        "        newcaption = clean_text(caption)\n",
        "        df['comment'].iloc[i] = newcaption\n",
        "        progress_bar.update(1)\n",
        "df['comment']"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Q4F-tYIb1w-q",
        "outputId": "6cab890e-9743-4d96-ebd1-7b4f624a236c"
      },
      "source": [
        "### EDA of vocabulary"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def df_word(df_txt):\n",
        "    vocabulary = []\n",
        "    for i in range(len(df_txt)):\n",
        "        temp=df_txt.iloc[i]\n",
        "        vocabulary.extend(temp.split())\n",
        "    print('Vocabulary Size: %d' % len(set(vocabulary)))\n",
        "    ct = Counter(vocabulary)\n",
        "    dfword = pd.DataFrame({\"word\":list(ct.keys()),\"count\":list(ct.values())})\n",
        "    dfword = dfword.sort_values(\"count\",ascending=False)\n",
        "    dfword = dfword.reset_index()[[\"word\",\"count\"]]\n",
        "    del vocabulary\n",
        "    return dfword\n",
        "\n",
        "dfword = df_word(df['comment'])\n",
        "\n",
        "topn = 25\n",
        "\n",
        "def plthist(dfsub, title=\"The top {} most frequently appearing words\".format(topn)):\n",
        "    plt.figure(figsize=(20,3))\n",
        "    plt.bar(dfsub.index,dfsub[\"count\"])\n",
        "    plt.yticks(fontsize=20)\n",
        "    plt.xticks(dfsub.index,dfsub[\"word\"],rotation=90,fontsize=20)\n",
        "    plt.title(title,fontsize=20)\n",
        "    plt.show()\n",
        "\n",
        "plthist(dfword.iloc[:topn,:],\n",
        "        title=\"The top {} most frequently appearing words\".format(topn))\n",
        "plthist(dfword.iloc[-topn:,:],\n",
        "        title=\"The least {} most frequently appearing words\".format(topn))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2Kiw9pRW6VSB"
      },
      "source": [
        "### Create word frequency"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KPodSMak1w-r"
      },
      "outputs": [],
      "source": [
        "word_freq = {}\n",
        "for caption in df['comment']:\n",
        "    caption = caption.strip()\n",
        "    for word in caption.split():\n",
        "        if word not in word_freq:\n",
        "            word_freq[word] = 0\n",
        "        word_freq[word] += 1"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5_qF-Fy96VSB"
      },
      "source": [
        "### Build vocabulary"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SKelBxFK1w-r",
        "outputId": "f244ced3-cde6-43f3-e96a-475ea035a1fc"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Vocabulary size: 2995\n"
          ]
        }
      ],
      "source": [
        "def build_vocab(captions, word_freq, count_threshold=5):\n",
        "\n",
        "    vocab = {\n",
        "        \"<pad>\": 0,\n",
        "        \"<unk>\": 1,\n",
        "        \"<sos>\": 2,\n",
        "        \"<eos>\": 3\n",
        "    }\n",
        "    index = 4\n",
        "\n",
        "    for caption in captions:\n",
        "        caption = caption.strip().split(\" \")\n",
        "        for word in caption:\n",
        "            if word and word_freq[word] >= count_threshold and word not in vocab:\n",
        "                vocab[word] = index\n",
        "                index += 1\n",
        "\n",
        "    inv_vocab = {v: k for k, v in vocab.items()}\n",
        "    return vocab, inv_vocab\n",
        "\n",
        "vocab, inv_vocab = build_vocab(df['comment'], word_freq)\n",
        "print(\"Vocabulary size: {}\".format(len(vocab)))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Qmwn1WVz6VSB"
      },
      "source": [
        "### Tokenize words into indices"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "GvkD1Nlq1w-t",
        "outputId": "614a1743-2eca-4110-8366-e76dd968972b"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "summary": "{\n  \"name\": \"df\",\n  \"rows\": 40455,\n  \"fields\": [\n    {\n      \"column\": \"image_name\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 8091,\n        \"samples\": [\n          \"3139895886_5a6d495b13.jpg\",\n          \"3133825703_359a0c414d.jpg\",\n          \"244910177_7c4ec3f65b.jpg\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"comment\",\n      \"properties\": {\n        \"dtype\": \"object\",\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}",
              "type": "dataframe",
              "variable_name": "df"
            },
            "text/html": [
              "\n",
              "  <div id=\"df-a9bc3cd6-7e62-429c-9a87-43f045756687\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>image_name</th>\n",
              "      <th>comment</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1000268201_693b08cb0e.jpg</td>\n",
              "      <td>[2, 4, 5, 6, 4, 7, 8, 9, 10, 11, 4, 12, 13, 14...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1000268201_693b08cb0e.jpg</td>\n",
              "      <td>[2, 4, 17, 18, 19, 4, 20, 21, 3, 0, 0, 0, 0, 0...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>1000268201_693b08cb0e.jpg</td>\n",
              "      <td>[2, 4, 22, 17, 10, 19, 4, 20, 23, 3, 0, 0, 0, ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>1000268201_693b08cb0e.jpg</td>\n",
              "      <td>[2, 4, 22, 17, 10, 24, 14, 25, 26, 23, 3, 0, 0...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>1000268201_693b08cb0e.jpg</td>\n",
              "      <td>[2, 4, 22, 17, 6, 4, 7, 8, 18, 19, 4, 20, 1, 3...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-a9bc3cd6-7e62-429c-9a87-43f045756687')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-a9bc3cd6-7e62-429c-9a87-43f045756687 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-a9bc3cd6-7e62-429c-9a87-43f045756687');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-fa8a7be1-9e20-4f25-a414-6c0ba48f619d\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-fa8a7be1-9e20-4f25-a414-6c0ba48f619d')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-fa8a7be1-9e20-4f25-a414-6c0ba48f619d button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "text/plain": [
              "                  image_name  \\\n",
              "0  1000268201_693b08cb0e.jpg   \n",
              "1  1000268201_693b08cb0e.jpg   \n",
              "2  1000268201_693b08cb0e.jpg   \n",
              "3  1000268201_693b08cb0e.jpg   \n",
              "4  1000268201_693b08cb0e.jpg   \n",
              "\n",
              "                                             comment  \n",
              "0  [2, 4, 5, 6, 4, 7, 8, 9, 10, 11, 4, 12, 13, 14...  \n",
              "1  [2, 4, 17, 18, 19, 4, 20, 21, 3, 0, 0, 0, 0, 0...  \n",
              "2  [2, 4, 22, 17, 10, 19, 4, 20, 23, 3, 0, 0, 0, ...  \n",
              "3  [2, 4, 22, 17, 10, 24, 14, 25, 26, 23, 3, 0, 0...  \n",
              "4  [2, 4, 22, 17, 6, 4, 7, 8, 18, 19, 4, 20, 1, 3...  "
            ]
          },
          "execution_count": 15,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "max_sen_len = 14\n",
        "def convert_captions(captions, vocab, max_length=max_sen_len+2):\n",
        "    tokens = [[vocab[\"<pad>\"]]*max_length for _ in range(len(captions))]\n",
        "    for i, caption in enumerate(captions):\n",
        "        caption = caption.strip().split()\n",
        "        tokens[i][0] = vocab[\"<sos>\"]\n",
        "        j = 1\n",
        "        for word in caption[:max_length-2]:\n",
        "            if word not in vocab:\n",
        "                tokens[i][j] = vocab[\"<unk>\"]\n",
        "            else:\n",
        "                tokens[i][j] = vocab[word]\n",
        "            j += 1\n",
        "        tokens[i][j] = vocab[\"<eos>\"]\n",
        "    return tokens\n",
        "df['comment'] = convert_captions(df['comment'], vocab)\n",
        "df.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VM9rOEQh6VSB"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AJXfxKEF6VSB"
      },
      "source": [
        "## Build Image Caption Dataset Class and helper functions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "a5-_4wVm6VSB"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "from PIL import Image\n",
        "\n",
        "IMG_DIR = \"/content/drive/MyDrive/archive (4)/Images\"\n",
        "preloaded_images = {}\n",
        "\n",
        "# Filter out directories from the list of files\n",
        "image_files = [filename for filename in os.listdir(IMG_DIR) if os.path.isfile(os.path.join(IMG_DIR, filename))]\n",
        "\n",
        "for filename in image_files:\n",
        "    img_path = os.path.join(IMG_DIR, filename)\n",
        "    with Image.open(img_path) as img:\n",
        "        preloaded_images[filename] = img.copy()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 83,
      "metadata": {
        "id": "H95fvu4q1w-t"
      },
      "outputs": [],
      "source": [
        "class ImageCaptionDataset(torch.utils.data.Dataset):\n",
        "    def __init__(self, root_dir, captions_csv, transform=None):\n",
        "        self.root_dir = root_dir\n",
        "        self.captions_csv = captions_csv\n",
        "        self.transform = transform\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.captions_csv)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        if torch.is_tensor(idx):\n",
        "            idx = idx.tolist()\n",
        "\n",
        "        img_name = os.path.join(self.root_dir, self.captions_csv.iloc[idx, 0])\n",
        "        image = Image.open(img_name)\n",
        "        if self.transform:\n",
        "            image = self.transform(image)\n",
        "\n",
        "        caption = torch.LongTensor(self.captions_csv.iloc[idx, 1]).to(device)\n",
        "\n",
        "        '''\n",
        "            Ensure that the method returns a dictionary with keys 'image' and 'caption'.\n",
        "        '''\n",
        "        sample = {'image': image, 'caption': caption}\n",
        "\n",
        "        return sample\n",
        "\n",
        "\n",
        "class ImageCaptionDataset(torch.utils.data.Dataset):\n",
        "    def __init__(self, root_dir, captions_csv, transform=None):\n",
        "        self.root_dir = root_dir\n",
        "        self.captions_csv = captions_csv\n",
        "        self.transform = transform\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.captions_csv)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        if torch.is_tensor(idx):\n",
        "            idx = idx.tolist()\n",
        "\n",
        "        img_name = self.captions_csv.iloc[idx, 0]\n",
        "        full_img_path = os.path.join(self.root_dir, img_name)\n",
        "        image = Image.open(full_img_path)\n",
        "        if self.transform:\n",
        "            image = self.transform(image)\n",
        "\n",
        "        caption = torch.LongTensor(self.captions_csv.iloc[idx, 1]).to(device)\n",
        "        sample = {'image': image, 'caption': caption, 'filename': img_name}\n",
        "\n",
        "        return sample"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "dSB1RZ9Q1w-u"
      },
      "outputs": [],
      "source": [
        "def unnormalizeImage(img):\n",
        "\n",
        "    if torch.is_tensor(img):\n",
        "        img = img.cpu().detach().clone().numpy()\n",
        "\n",
        "    img[0] = img[0] * 0.229\n",
        "    img[1] = img[1] * 0.224\n",
        "    img[2] = img[2] * 0.225\n",
        "    img[0] += 0.485\n",
        "    img[1] += 0.456\n",
        "    img[2] += 0.406\n",
        "\n",
        "    img = img.transpose((1, 2, 0))\n",
        "\n",
        "    return img"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fOaQv2tP6VSC"
      },
      "source": [
        "### Generate dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "IaG7v23L1w-u",
        "outputId": "d62c4329-3702-4c24-f263-90b207f9ff7f"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "<__main__.ImageCaptionDataset at 0x7c8d77c6fc10>"
            ]
          },
          "execution_count": 19,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "\n",
        "TRANSFORM_IMG = torchvision.transforms.Compose([\n",
        "    torchvision.transforms.Resize(224),\n",
        "    torchvision.transforms.CenterCrop(224),\n",
        "    torchvision.transforms.ToTensor(),\n",
        "    torchvision.transforms.Normalize((0.485, 0.456, 0.406),(0.229, 0.224, 0.225))\n",
        "    ])\n",
        "flickr_dataset = ImageCaptionDataset(root_dir=IMG_DIR, captions_csv=df, transform=TRANSFORM_IMG)\n",
        "flickr_dataset\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "s0St9MaO6VSC"
      },
      "source": [
        "### Train-Dev-Test split"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "K4_hC5aY1w-v",
        "outputId": "0906fb06-1105-4159-eb7d-2b3cdadb0f9b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "no of batches in train set: 365\n",
            "no of batches in valid set: 21\n",
            "no of batches in test set: 21\n"
          ]
        }
      ],
      "source": [
        "BATCH_SIZE = 100\n",
        "NUM_WORKERS = 0\n",
        "\n",
        "n_val = int(np.floor(0.05 * len(flickr_dataset)))\n",
        "n_test = int(np.floor(0.05 * len(flickr_dataset)))\n",
        "n_train = len(flickr_dataset) - n_val - n_test\n",
        "dl_args = dict(batch_size=BATCH_SIZE, num_workers=NUM_WORKERS, shuffle=True)\n",
        "\n",
        "train_ds, val_ds, test_ds = random_split(flickr_dataset, [n_train, n_val, n_test], generator=torch.Generator().manual_seed(20))\n",
        "\n",
        "train_dl = DataLoader(train_ds, **dl_args)\n",
        "valid_dl = DataLoader(val_ds, **dl_args)\n",
        "test_dl = DataLoader(test_ds, **dl_args)\n",
        "\n",
        "print(\"no of batches in train set: {}\".format(len(train_dl)))\n",
        "print(\"no of batches in valid set: {}\".format(len(valid_dl)))\n",
        "print(\"no of batches in test set: {}\".format(len(test_dl)))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aL7cAn7Y6VSC"
      },
      "source": [
        "## Build Model\n",
        "\n",
        "The block diagram of model is shown below:\n",
        "\n",
        "![Image Caption Model - Block Diagram](attachment:16932c49-e15a-4847-bf74-991dcb10158a.png)\n",
        "\n",
        "### Image Encoder Class"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "IVfl6LS_1w-w"
      },
      "outputs": [],
      "source": [
        "class ImageEncoder(nn.Module):\n",
        "    def __init__(self, hidd_dim):\n",
        "        super().__init__()\n",
        "        self.cnn = torch.nn.Sequential(*(list(torchvision.models.resnet101(pretrained=True).children())[:-1]),\n",
        "                                      nn.Flatten())\n",
        "        self.cnn.eval()\n",
        "        self.fc = nn.Linear(2048, hidd_dim)\n",
        "\n",
        "    def forward(self, img):\n",
        "        img = self.cnn(img)\n",
        "        img = self.fc(img)\n",
        "        return img"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dWAnUsuS6VSC"
      },
      "source": [
        "### Caption Decoder Class"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "ggszm_Qb1w-x"
      },
      "outputs": [],
      "source": [
        "class CaptionDecoder(nn.Module):\n",
        "    def __init__(self, n_vocab, hidd_dim, max_sen_len, emb_dim, p):\n",
        "        super().__init__()\n",
        "        self.max_sen_len = max_sen_len\n",
        "        self.emb = nn.Embedding(num_embeddings=n_vocab, embedding_dim=emb_dim, padding_idx=0)\n",
        "\n",
        "        self.lstm = nn.LSTM(input_size=emb_dim,\n",
        "                            hidden_size=hidd_dim,\n",
        "                            num_layers=1,\n",
        "                            batch_first=True,\n",
        "                            bidirectional=False,\n",
        "                            dropout=p)\n",
        "        self.fc_text = nn.Linear(hidd_dim, n_vocab)\n",
        "        self.soft = nn.Softmax(dim=-1)\n",
        "\n",
        "    def forward(self, x, img, predict_mode=False):\n",
        "        img = torch.stack([img]*(self.lstm.num_layers), dim=0).to(device)\n",
        "        if predict_mode:\n",
        "            output = []\n",
        "            h0 = img\n",
        "            c0 = img\n",
        "            while x != vocab[\"<eos>\"] and len(output) <= self.max_sen_len:\n",
        "                x = torch.tensor([[x]]).to(device)\n",
        "                x = self.emb(x)\n",
        "                out, (h0, c0) = self.lstm(x, (h0, c0))\n",
        "                out = self.fc_text(out)\n",
        "                out = self.soft(out)\n",
        "                out = torch.argmax(out, dim=-1)\n",
        "                x = out.squeeze().item()\n",
        "                output.append(x)\n",
        "            output = torch.tensor(output).to(device)\n",
        "        else:\n",
        "            x = self.emb(x)\n",
        "            output, (h0, c0) = self.lstm(x, (img, img))\n",
        "            output = self.fc_text(output)\n",
        "        return output"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZHjnKeCB6VSC"
      },
      "source": [
        "### Image Caption Model Class"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "UR3ZJV5U1w-y"
      },
      "outputs": [],
      "source": [
        "class ImgCaptionModel(nn.Module):\n",
        "    def __init__(self, n_vocab, hidd_dim, max_sen_len, emb_dim, p=0):\n",
        "        super().__init__()\n",
        "        self.encoder = ImageEncoder(hidd_dim).to(device)\n",
        "        self.decoder = CaptionDecoder(n_vocab, hidd_dim, max_sen_len, emb_dim, p).to(device)\n",
        "\n",
        "    def predict(self, img):\n",
        "        img = self.encoder(img)\n",
        "        cap = vocab[\"<sos>\"]\n",
        "        yhat = self.decoder(cap, img, predict_mode=True)\n",
        "\n",
        "        pred_sen = [inv_vocab[t.item()] for t in yhat]\n",
        "        pred_sen = \" \".join(pred_sen)\n",
        "        return pred_sen\n",
        "\n",
        "    def forward(self, sample):\n",
        "        '''\n",
        "            sample: dict of image & caption\n",
        "        '''\n",
        "        img = sample['image'].to(device)\n",
        "        cap = sample['caption'].to(device)\n",
        "\n",
        "        '''---For Image---'''\n",
        "        img = self.encoder(img)\n",
        "\n",
        "        '''---For Text---'''\n",
        "        yhat = self.decoder(cap[:, :-1], img, predict_mode=False)\n",
        "        yhat = yhat.permute(0, 2, 1)\n",
        "        return yhat"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RabgrlNi6VSC"
      },
      "source": [
        "### Define helper functions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "mQM8tjhx1w-z"
      },
      "outputs": [],
      "source": [
        "def train(model, sample, loss_fn, optimizer):\n",
        "    model.train()\n",
        "\n",
        "    cap = sample['caption'].to(device)\n",
        "    yhat = model(sample)\n",
        "\n",
        "    loss = loss_fn(yhat, cap[:,1:])\n",
        "    optimizer.zero_grad()\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "\n",
        "    return loss.item()\n",
        "\n",
        "def test(model, sample, i, loss_fn):\n",
        "    model.eval()\n",
        "    with torch.no_grad():\n",
        "        cap = sample['caption'].to(device)\n",
        "        yhat = model(sample)\n",
        "        loss = loss_fn(yhat, cap[:,1:])\n",
        "\n",
        "    return loss.item()\n",
        "\n",
        "def predict(model, sample, i, plot_img=False):\n",
        "    model.eval()\n",
        "    with torch.no_grad():\n",
        "        img = sample['image'][i].to(device)\n",
        "        if plot_img:\n",
        "            plt.imshow(unnormalizeImage(img))\n",
        "            plt.xticks([])\n",
        "            plt.yticks([])\n",
        "            plt.show()\n",
        "        pred_sen = model.predict(img.unsqueeze(0))\n",
        "\n",
        "    return pred_sen\n",
        "\n",
        "def sample_output(model, ds=test_ds):\n",
        "    with torch.no_grad():\n",
        "        j = np.random.randint(low=0,high=len(ds))\n",
        "        img = ds[j]['image']\n",
        "        true_ans = ds[j]['caption']\n",
        "        sp = {'image': img.unsqueeze(0), 'caption':true_ans.unsqueeze(0)}\n",
        "        pred_ans = predict(model, sp, 0, plot_img=True)\n",
        "\n",
        "        true_ans = [inv_vocab[t.item()] for t in true_ans if t not in [0,2,3]]\n",
        "        rc = [true_ans]\n",
        "        true_ans = \" \".join(true_ans)\n",
        "        print(\"true: {}\".format(true_ans))\n",
        "        print(\"prediction: {}\".format(pred_ans))\n",
        "\n",
        "        #bleu scores\n",
        "        cc = pred_ans.split(' ')\n",
        "        cc = [ps for ps in cc if ps not in ['<sos>', '<eos>', '<pad>']]\n",
        "        b1 = sentence_bleu(rc,cc,weights=(1,0,0,0))\n",
        "        b2 = sentence_bleu(rc,cc,weights=(0.5,0.5,0,0))\n",
        "        b3 = sentence_bleu(rc,cc,weights=(1/3,1/3,1/3,0))\n",
        "        b4 = sentence_bleu(rc,cc,weights=(0.25, 0.25, 0.25, 0.25))\n",
        "        print(\"BLEU-1: {:.2f}\\nBLEU-2: {:.2f}\\nBLEU-3: {:.2f}\\nBLEU-4: {:.2f}\".format(b1,b2,b3,b4))\n",
        "\n",
        "\n",
        "        #rouge scores\n",
        "        scorer = rouge_scorer.RougeScorer(['rouge1', 'rouge2', 'rougeL'], use_stemmer=True)\n",
        "        pred_ans = pred_ans.split(' ')\n",
        "        pred_ans = \" \".join([p for p in pred_ans if p not in ['<sos>', '<eos>', '<pad>']])\n",
        "        r = scorer.score(true_ans,pred_ans)\n",
        "        r1 = r['rouge1']\n",
        "        r2 = r['rouge2']\n",
        "        rl = r['rougeL']\n",
        "        print(\"ROUGE-1: {}\\nROUGE-2: {}\\nROUGE-l: {}\".format(r1,r2,rl))\n",
        "\n",
        "        #meteor scores\n",
        "        m1 = nltk.translate.meteor_score.meteor_score([[true_ans]],[pred_ans])\n",
        "        print(\"METEOR: {:.2f}\".format(m1))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8NlZpxBB6VSD"
      },
      "source": [
        "## Training the Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "G9L81oiJ1w-z",
        "outputId": "d1a9e249-289a-4a42-eb46-a911793a1761",
        "scrolled": true
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Downloading: \"https://download.pytorch.org/models/resnet101-63fe2227.pth\" to /root/.cache/torch/hub/checkpoints/resnet101-63fe2227.pth\n",
            "100%|██████████| 171M/171M [00:01<00:00, 167MB/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "ImgCaptionModel(\n",
            "  (encoder): ImageEncoder(\n",
            "    (cnn): Sequential(\n",
            "      (0): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
            "      (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (2): ReLU(inplace=True)\n",
            "      (3): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
            "      (4): Sequential(\n",
            "        (0): Bottleneck(\n",
            "          (conv1): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "          (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "          (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "          (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (relu): ReLU(inplace=True)\n",
            "          (downsample): Sequential(\n",
            "            (0): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "            (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          )\n",
            "        )\n",
            "        (1): Bottleneck(\n",
            "          (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "          (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "          (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "          (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (relu): ReLU(inplace=True)\n",
            "        )\n",
            "        (2): Bottleneck(\n",
            "          (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "          (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "          (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "          (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (relu): ReLU(inplace=True)\n",
            "        )\n",
            "      )\n",
            "      (5): Sequential(\n",
            "        (0): Bottleneck(\n",
            "          (conv1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "          (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
            "          (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "          (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (relu): ReLU(inplace=True)\n",
            "          (downsample): Sequential(\n",
            "            (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
            "            (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          )\n",
            "        )\n",
            "        (1): Bottleneck(\n",
            "          (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "          (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "          (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "          (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (relu): ReLU(inplace=True)\n",
            "        )\n",
            "        (2): Bottleneck(\n",
            "          (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "          (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "          (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "          (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (relu): ReLU(inplace=True)\n",
            "        )\n",
            "        (3): Bottleneck(\n",
            "          (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "          (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "          (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "          (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (relu): ReLU(inplace=True)\n",
            "        )\n",
            "      )\n",
            "      (6): Sequential(\n",
            "        (0): Bottleneck(\n",
            "          (conv1): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
            "          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (relu): ReLU(inplace=True)\n",
            "          (downsample): Sequential(\n",
            "            (0): Conv2d(512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
            "            (1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          )\n",
            "        )\n",
            "        (1): Bottleneck(\n",
            "          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (relu): ReLU(inplace=True)\n",
            "        )\n",
            "        (2): Bottleneck(\n",
            "          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (relu): ReLU(inplace=True)\n",
            "        )\n",
            "        (3): Bottleneck(\n",
            "          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (relu): ReLU(inplace=True)\n",
            "        )\n",
            "        (4): Bottleneck(\n",
            "          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (relu): ReLU(inplace=True)\n",
            "        )\n",
            "        (5): Bottleneck(\n",
            "          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (relu): ReLU(inplace=True)\n",
            "        )\n",
            "        (6): Bottleneck(\n",
            "          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (relu): ReLU(inplace=True)\n",
            "        )\n",
            "        (7): Bottleneck(\n",
            "          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (relu): ReLU(inplace=True)\n",
            "        )\n",
            "        (8): Bottleneck(\n",
            "          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (relu): ReLU(inplace=True)\n",
            "        )\n",
            "        (9): Bottleneck(\n",
            "          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (relu): ReLU(inplace=True)\n",
            "        )\n",
            "        (10): Bottleneck(\n",
            "          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (relu): ReLU(inplace=True)\n",
            "        )\n",
            "        (11): Bottleneck(\n",
            "          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (relu): ReLU(inplace=True)\n",
            "        )\n",
            "        (12): Bottleneck(\n",
            "          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (relu): ReLU(inplace=True)\n",
            "        )\n",
            "        (13): Bottleneck(\n",
            "          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (relu): ReLU(inplace=True)\n",
            "        )\n",
            "        (14): Bottleneck(\n",
            "          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (relu): ReLU(inplace=True)\n",
            "        )\n",
            "        (15): Bottleneck(\n",
            "          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (relu): ReLU(inplace=True)\n",
            "        )\n",
            "        (16): Bottleneck(\n",
            "          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (relu): ReLU(inplace=True)\n",
            "        )\n",
            "        (17): Bottleneck(\n",
            "          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (relu): ReLU(inplace=True)\n",
            "        )\n",
            "        (18): Bottleneck(\n",
            "          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (relu): ReLU(inplace=True)\n",
            "        )\n",
            "        (19): Bottleneck(\n",
            "          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (relu): ReLU(inplace=True)\n",
            "        )\n",
            "        (20): Bottleneck(\n",
            "          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (relu): ReLU(inplace=True)\n",
            "        )\n",
            "        (21): Bottleneck(\n",
            "          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (relu): ReLU(inplace=True)\n",
            "        )\n",
            "        (22): Bottleneck(\n",
            "          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (relu): ReLU(inplace=True)\n",
            "        )\n",
            "      )\n",
            "      (7): Sequential(\n",
            "        (0): Bottleneck(\n",
            "          (conv1): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "          (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
            "          (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "          (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (relu): ReLU(inplace=True)\n",
            "          (downsample): Sequential(\n",
            "            (0): Conv2d(1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
            "            (1): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          )\n",
            "        )\n",
            "        (1): Bottleneck(\n",
            "          (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "          (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "          (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "          (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (relu): ReLU(inplace=True)\n",
            "        )\n",
            "        (2): Bottleneck(\n",
            "          (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "          (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "          (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "          (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (relu): ReLU(inplace=True)\n",
            "        )\n",
            "      )\n",
            "      (8): AdaptiveAvgPool2d(output_size=(1, 1))\n",
            "      (9): Flatten(start_dim=1, end_dim=-1)\n",
            "    )\n",
            "    (fc): Linear(in_features=2048, out_features=512, bias=True)\n",
            "  )\n",
            "  (decoder): CaptionDecoder(\n",
            "    (emb): Embedding(2995, 32, padding_idx=0)\n",
            "    (lstm): LSTM(32, 512, batch_first=True)\n",
            "    (fc_text): Linear(in_features=512, out_features=2995, bias=True)\n",
            "    (soft): Softmax(dim=-1)\n",
            "  )\n",
            ")\n"
          ]
        }
      ],
      "source": [
        "model = ImgCaptionModel(n_vocab=len(vocab), hidd_dim=512, max_sen_len=max_sen_len+2, emb_dim=32, p=0).to(device)\n",
        "loss_fn = nn.CrossEntropyLoss()\n",
        "optimizer = torch.optim.Adam(model.parameters())\n",
        "epochs = 30\n",
        "print(model)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "G5-mc8PT1w-0",
        "outputId": "5498c2e7-e5b2-4c56-a636-78ab1b55dab2"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "--- Epoch 1 ---\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 365/365 [07:59<00:00,  1.31s/it]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\tLoss (Training) : 3.3863718045900946\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 21/21 [00:00<00:00, 42.77it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\tLoss (Validation) : 3.066277821858724\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 2022/2022 [01:26<00:00, 23.39it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "--- Epoch 2 ---\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 365/365 [07:56<00:00,  1.31s/it]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\tLoss (Training) : 2.690656629327225\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 21/21 [00:00<00:00, 43.46it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\tLoss (Validation) : 2.7489850634620305\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 2022/2022 [01:25<00:00, 23.71it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "--- Epoch 3 ---\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 365/365 [07:55<00:00,  1.30s/it]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\tLoss (Training) : 2.4685250047135026\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 21/21 [00:00<00:00, 42.92it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\tLoss (Validation) : 2.12019673983256\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 2022/2022 [01:25<00:00, 23.61it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "--- Epoch 4 ---\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 365/365 [07:55<00:00,  1.30s/it]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\tLoss (Training) : 2.332684455505789\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 21/21 [00:00<00:00, 43.65it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\tLoss (Validation) : 2.240424621672857\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 2022/2022 [01:23<00:00, 24.29it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "--- Epoch 5 ---\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 365/365 [07:53<00:00,  1.30s/it]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\tLoss (Training) : 2.23215793550831\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 21/21 [00:00<00:00, 43.68it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\tLoss (Validation) : 2.2110943567185175\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 2022/2022 [01:23<00:00, 24.13it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "--- Epoch 6 ---\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 365/365 [07:53<00:00,  1.30s/it]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\tLoss (Training) : 2.149567209857784\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 21/21 [00:00<00:00, 43.38it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\tLoss (Validation) : 1.8936368340537661\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 2022/2022 [01:22<00:00, 24.37it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "--- Epoch 7 ---\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 365/365 [07:52<00:00,  1.29s/it]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\tLoss (Training) : 2.0750988653261366\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 21/21 [00:00<00:00, 43.39it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\tLoss (Validation) : 1.793959827650161\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 2022/2022 [01:23<00:00, 24.25it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "--- Epoch 8 ---\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 365/365 [07:52<00:00,  1.29s/it]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\tLoss (Training) : 2.00981966534706\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 21/21 [00:00<00:00, 43.60it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\tLoss (Validation) : 2.1771314711797807\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 2022/2022 [01:24<00:00, 24.03it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "--- Epoch 9 ---\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 365/365 [07:49<00:00,  1.29s/it]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\tLoss (Training) : 1.9482632748068196\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 21/21 [00:00<00:00, 43.79it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\tLoss (Validation) : 1.7972163018726168\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 2022/2022 [01:21<00:00, 24.86it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "--- Epoch 10 ---\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 365/365 [07:49<00:00,  1.29s/it]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\tLoss (Training) : 1.8880198468900706\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 21/21 [00:00<00:00, 43.11it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\tLoss (Validation) : 1.6805741786956787\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 2022/2022 [01:22<00:00, 24.48it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "--- Epoch 11 ---\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 365/365 [07:47<00:00,  1.28s/it]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\tLoss (Training) : 1.8299752885348177\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 21/21 [00:00<00:00, 43.63it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\tLoss (Validation) : 1.707581877708435\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 2022/2022 [01:21<00:00, 24.94it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "--- Epoch 12 ---\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 365/365 [07:46<00:00,  1.28s/it]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\tLoss (Training) : 1.7755276180293462\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 21/21 [00:00<00:00, 43.05it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\tLoss (Validation) : 1.6568382070178078\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 2022/2022 [01:20<00:00, 25.19it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "--- Epoch 13 ---\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 365/365 [07:46<00:00,  1.28s/it]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\tLoss (Training) : 1.7221854415658402\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 21/21 [00:00<00:00, 43.68it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\tLoss (Validation) : 1.729043268022083\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 2022/2022 [01:20<00:00, 25.18it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "--- Epoch 14 ---\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 365/365 [07:48<00:00,  1.28s/it]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\tLoss (Training) : 1.670703486873679\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 21/21 [00:00<00:00, 42.93it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\tLoss (Validation) : 1.3203526508240473\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 2022/2022 [01:21<00:00, 24.73it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "--- Epoch 15 ---\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 365/365 [07:47<00:00,  1.28s/it]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\tLoss (Training) : 1.6202641660220003\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 21/21 [00:00<00:00, 43.48it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\tLoss (Validation) : 1.5185391108194988\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 2022/2022 [01:21<00:00, 24.69it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "--- Epoch 16 ---\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 365/365 [07:52<00:00,  1.29s/it]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\tLoss (Training) : 1.5724799361947464\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 21/21 [00:00<00:00, 43.48it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\tLoss (Validation) : 1.3361237049102783\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 2022/2022 [01:22<00:00, 24.61it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "--- Epoch 17 ---\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 365/365 [07:53<00:00,  1.30s/it]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\tLoss (Training) : 1.5287784151834984\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 21/21 [00:00<00:00, 43.16it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\tLoss (Validation) : 1.186837605067662\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 2022/2022 [01:22<00:00, 24.48it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "--- Epoch 18 ---\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 365/365 [07:53<00:00,  1.30s/it]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\tLoss (Training) : 1.4820752055677648\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 21/21 [00:00<00:00, 43.55it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\tLoss (Validation) : 1.3793459790093558\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 2022/2022 [01:23<00:00, 24.20it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "--- Epoch 19 ---\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 365/365 [07:57<00:00,  1.31s/it]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\tLoss (Training) : 1.4411534564135826\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 21/21 [00:00<00:00, 43.58it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\tLoss (Validation) : 1.430549286660694\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 2022/2022 [01:24<00:00, 24.05it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "--- Epoch 20 ---\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 365/365 [07:51<00:00,  1.29s/it]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\tLoss (Training) : 1.3985447194478282\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 21/21 [00:00<00:00, 43.38it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\tLoss (Validation) : 1.3177496194839478\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 2022/2022 [01:23<00:00, 24.30it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "--- Epoch 21 ---\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 365/365 [07:53<00:00,  1.30s/it]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\tLoss (Training) : 1.3582332127714811\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 21/21 [00:00<00:00, 43.51it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\tLoss (Validation) : 1.1946719884872437\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 2022/2022 [01:22<00:00, 24.45it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "--- Epoch 22 ---\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 365/365 [07:50<00:00,  1.29s/it]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\tLoss (Training) : 1.3198806553670805\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 21/21 [00:00<00:00, 43.56it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\tLoss (Validation) : 1.2048278479349046\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 2022/2022 [01:21<00:00, 24.72it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "--- Epoch 23 ---\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 365/365 [07:52<00:00,  1.29s/it]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\tLoss (Training) : 1.280642923916856\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 21/21 [00:00<00:00, 43.26it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\tLoss (Validation) : 0.9321740354810443\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 2022/2022 [01:21<00:00, 24.84it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "--- Epoch 24 ---\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 365/365 [07:47<00:00,  1.28s/it]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\tLoss (Training) : 1.2440481770528506\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 21/21 [00:00<00:00, 43.54it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\tLoss (Validation) : 0.9964584537914821\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 2022/2022 [01:21<00:00, 24.70it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "--- Epoch 25 ---\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 365/365 [07:56<00:00,  1.30s/it]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\tLoss (Training) : 1.2094492784918172\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 21/21 [00:00<00:00, 43.51it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\tLoss (Validation) : 1.1047599031811668\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 2022/2022 [01:25<00:00, 23.59it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "--- Epoch 26 ---\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 365/365 [07:53<00:00,  1.30s/it]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\tLoss (Training) : 1.1768442104940544\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 21/21 [00:00<00:00, 42.97it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\tLoss (Validation) : 0.8624797633716038\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 2022/2022 [01:21<00:00, 24.68it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "--- Epoch 27 ---\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 365/365 [07:48<00:00,  1.28s/it]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\tLoss (Training) : 1.1443519219960252\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 21/21 [00:00<00:00, 43.58it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\tLoss (Validation) : 0.9510430835542225\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 2022/2022 [01:22<00:00, 24.38it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "--- Epoch 28 ---\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 365/365 [07:48<00:00,  1.28s/it]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\tLoss (Training) : 1.1100248585008594\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 21/21 [00:00<00:00, 43.63it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\tLoss (Validation) : 1.0172621919995262\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 2022/2022 [01:22<00:00, 24.58it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "--- Epoch 29 ---\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 365/365 [07:49<00:00,  1.29s/it]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\tLoss (Training) : 1.079548933897933\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 21/21 [00:00<00:00, 43.39it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\tLoss (Validation) : 0.9489940234592983\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 2022/2022 [01:21<00:00, 24.73it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "--- Epoch 30 ---\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 365/365 [07:49<00:00,  1.29s/it]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\tLoss (Training) : 1.051004893975715\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 21/21 [00:00<00:00, 42.75it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\tLoss (Validation) : 0.8369755943616232\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 2022/2022 [01:22<00:00, 24.62it/s]\n"
          ]
        }
      ],
      "source": [
        "train_loss = []\n",
        "valid_loss = []\n",
        "B1 = []\n",
        "B2 = []\n",
        "B3 = []\n",
        "B4 = []\n",
        "R1 = []\n",
        "R2 = []\n",
        "RL = []\n",
        "M = []\n",
        "best_loss = torch.inf\n",
        "best_model = dict()\n",
        "\n",
        "for i in range(epochs):\n",
        "    '''\n",
        "    Training on train set\n",
        "    '''\n",
        "    print(\"--- Epoch {} ---\".format(i+1))\n",
        "    epoch_loss = 0\n",
        "    m = len(train_dl)\n",
        "    with tqdm(total=m) as progress_bar:\n",
        "        for sample in train_dl:\n",
        "            epoch_loss += train(model, sample, loss_fn, optimizer)\n",
        "            progress_bar.update(1)\n",
        "    print(\"\\tLoss (Training) : {}\".format(epoch_loss/m))\n",
        "    train_loss.append(epoch_loss/m)\n",
        "\n",
        "    '''\n",
        "    Testing on dev set\n",
        "    '''\n",
        "    val_loss = 0\n",
        "    with tqdm(total=len(valid_dl)) as progress_bar1:\n",
        "        for j in range(len(valid_dl)):\n",
        "            vl = test(model, sample, j, loss_fn)\n",
        "            if vl < best_loss:\n",
        "                best_loss = vl\n",
        "                best_model = model.state_dict()\n",
        "            val_loss += vl\n",
        "            progress_bar1.update(1)\n",
        "    print(\"\\tLoss (Validation) : {}\".format(val_loss/len(valid_dl)))\n",
        "    valid_loss.append(val_loss/len(valid_dl))\n",
        "\n",
        "    '''\n",
        "    Computing sentence generation metrics on dev set\n",
        "    '''\n",
        "    with tqdm(total=len(val_ds)) as progress_bar2:\n",
        "        for j in range(len(val_ds)):\n",
        "            with torch.no_grad():\n",
        "                img = val_ds[j]['image']\n",
        "                true_ans = val_ds[j]['caption']\n",
        "                sp = {'image': img.unsqueeze(0), 'caption':true_ans.unsqueeze(0)}\n",
        "                pred_ans = predict(model, sp, 0)\n",
        "\n",
        "                true_ans = [inv_vocab[t.item()] for t in true_ans if t not in [0,2,3]]\n",
        "                rc = [true_ans]\n",
        "                true_ans = \" \".join(true_ans)\n",
        "\n",
        "                # bleu scores\n",
        "                cc = pred_ans.split(' ')\n",
        "                cc = [ps for ps in cc if ps not in ['<sos>', '<eos>', '<pad>']]\n",
        "                b1 = sentence_bleu(rc,cc,weights=(1,0,0,0))\n",
        "                b2 = sentence_bleu(rc,cc,weights=(0.5,0.5,0,0))\n",
        "                b3 = sentence_bleu(rc,cc,weights=(1/3,1/3,1/3,0))\n",
        "                b4 = sentence_bleu(rc,cc,weights=(0.25, 0.25, 0.25, 0.25))\n",
        "                B1.append(b1)\n",
        "                B2.append(b2)\n",
        "                B3.append(b3)\n",
        "                B4.append(b4)\n",
        "\n",
        "                # rouge scores\n",
        "                scorer = rouge_scorer.RougeScorer(['rouge1', 'rouge2', 'rougeL'], use_stemmer=True)\n",
        "                pred_ans = pred_ans.split(' ')\n",
        "                pred_ans = \" \".join([p for p in pred_ans if p not in ['<sos>', '<eos>', '<pad>']])\n",
        "                r = scorer.score(true_ans, pred_ans)\n",
        "                r1 = r['rouge1']\n",
        "                r2 = r['rouge2']\n",
        "                rl = r['rougeL']\n",
        "                R1.append(r1.fmeasure)\n",
        "                R2.append(r2.fmeasure)\n",
        "                RL.append(rl.fmeasure)\n",
        "\n",
        "                # meteor scores\n",
        "                m1 = nltk.translate.meteor_score.meteor_score([[true_ans]], [pred_ans])\n",
        "                M.append(m1)\n",
        "            progress_bar2.update(1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dqGv4kr66VSI"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4hyYeLLj6VSI"
      },
      "source": [
        "## Save results & best model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "plt.plot(range(len(train_loss)),train_loss, label='train loss')\n",
        "plt.plot(range(len(valid_loss)),valid_loss, label='val loss')\n",
        "plt.title(\"Learning curves\")\n",
        "plt.legend(loc='best')\n",
        "plt.xlabel('epochs')\n",
        "plt.ylabel('loss')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LHmKPPNgvqBv",
        "outputId": "7442b2aa-4097-47da-8f22-9ed8afe78372"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Weights of best model saved successfully!\n"
          ]
        }
      ],
      "source": [
        "torch.save(best_model, 'best_model_weights8k.h5')\n",
        "print(\"Weights of best model saved successfully!\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iLblRdWYpXsr",
        "outputId": "b7489946-527b-4b38-ec40-4a6149224787"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Results saved successfully!\n"
          ]
        }
      ],
      "source": [
        "def process_results(res):\n",
        "    r = []\n",
        "    m = int(res.shape[0]/epochs)\n",
        "    for i in range(epochs):\n",
        "        r.append(res[i*m:(i+1)*m].to_numpy())\n",
        "    r = np.array(r).mean(axis=1)\n",
        "    return r\n",
        "\n",
        "df_metrics = pd.DataFrame({\n",
        "    'B1':B1,\n",
        "    'B2':B2,\n",
        "    'B3':B3,\n",
        "    'B4':B4,\n",
        "    'R1':R1,\n",
        "    'R2':R2,\n",
        "    'RL':RL,\n",
        "    'M':M\n",
        "})\n",
        "df_metrics = df_metrics.apply(process_results,axis=0)*100\n",
        "df_metrics.to_csv('results8k.csv', index=False)\n",
        "\n",
        "df_loss = pd.DataFrame({\n",
        "    'train_loss':train_loss,\n",
        "    'valid_loss':valid_loss\n",
        "})\n",
        "df_loss = df_loss.apply(process_results,axis=0)\n",
        "df_loss.to_csv('loss8k.csv', index=False)\n",
        "print(\"Results saved successfully!\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hEYOZjnV6VSI"
      },
      "source": [
        "### Plot results"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "x = range(epochs)\n",
        "plt.figure(figsize=(15,7))\n",
        "plt.plot(x, df_metrics['B1'], label='BLEU-1', marker='.')\n",
        "plt.plot(x, df_metrics['B2'], label='BLEU-2', marker='.')\n",
        "plt.plot(x, df_metrics['B3'], label='BLEU-3', marker='.')\n",
        "plt.plot(x, df_metrics['B4'], label='BLEU-4', marker='.')\n",
        "plt.plot(x, df_metrics['R1'], label='ROUGE-1', marker='.')\n",
        "plt.plot(x, df_metrics['R2'], label='ROUGE-2', marker='.')\n",
        "plt.plot(x, df_metrics['RL'], label='ROUGE-L', marker='.')\n",
        "plt.plot(x, df_metrics['M'], label='METEOR', marker='.')\n",
        "plt.title(\"Results of evaluation metrics on dev set\")\n",
        "plt.legend(loc='lower center', bbox_to_anchor=(1.1, 0.3), ncol=1).get_frame().set_linewidth(0.0)\n",
        "plt.grid(axis='y')\n",
        "\n",
        "for c in df_metrics.columns.tolist():\n",
        "    for idx,val in enumerate(df_metrics[c].to_numpy()):\n",
        "        plt.text(idx,val+0.5, str(np.round_(val,2)), color='black', fontsize=6)\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AuRUaUGy6VSJ"
      },
      "source": [
        "## Generate sample outputs from test set using best weights"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Du07dMyWtVLR",
        "outputId": "60edf9f3-cc66-477a-844d-5cb78e8e93f7"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Best weights loaded successfully!\n"
          ]
        }
      ],
      "source": [
        "bestmodel = ImgCaptionModel(n_vocab=len(vocab), hidd_dim=512, max_sen_len=16, emb_dim=32, p=0).to(device)\n",
        "bestmodel.load_state_dict(torch.load('./best_model_weights8k.h5'))\n",
        "print(\"Best weights loaded successfully!\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Run this for sample output\n",
        "sample_output(bestmodel)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EV_ArDrS6VSJ",
        "outputId": "afcb7169-ff6c-4c57-b124-95a698bd8a0b"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "['.config',\n",
              " 'loss8k.csv',\n",
              " 'results8k.csv',\n",
              " 'best_model_weights8k.h5',\n",
              " 'drive',\n",
              " 'sample_data']"
            ]
          },
          "execution_count": 37,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "import os\n",
        "os.listdir('.')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 40,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "id": "flk3-U3ACa-a",
        "outputId": "c3998e74-7cd8-41c0-c611-251460483912"
      },
      "outputs": [
        {
          "data": {
            "application/javascript": "\n    async function download(id, filename, size) {\n      if (!google.colab.kernel.accessAllowed) {\n        return;\n      }\n      const div = document.createElement('div');\n      const label = document.createElement('label');\n      label.textContent = `Downloading \"${filename}\": `;\n      div.appendChild(label);\n      const progress = document.createElement('progress');\n      progress.max = size;\n      div.appendChild(progress);\n      document.body.appendChild(div);\n\n      const buffers = [];\n      let downloaded = 0;\n\n      const channel = await google.colab.kernel.comms.open(id);\n      // Send a message to notify the kernel that we're ready.\n      channel.send({})\n\n      for await (const message of channel.messages) {\n        // Send a message to notify the kernel that we're ready.\n        channel.send({})\n        if (message.buffers) {\n          for (const buffer of message.buffers) {\n            buffers.push(buffer);\n            downloaded += buffer.byteLength;\n            progress.value = downloaded;\n          }\n        }\n      }\n      const blob = new Blob(buffers, {type: 'application/binary'});\n      const a = document.createElement('a');\n      a.href = window.URL.createObjectURL(blob);\n      a.download = filename;\n      div.appendChild(a);\n      a.click();\n      div.remove();\n    }\n  ",
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/javascript": "download(\"download_5e8be966-b379-4366-9351-e2c8041fe240\", \"best_model_weights8k.h5\", 185842488)",
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "from google.colab import files\n",
        " # Download the results CSV file\n",
        "files.download('best_model_weights8k.h5')    # Download the loss CSV file\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 49,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OsW2q1F1C_M-",
        "outputId": "9c7e4eb8-9c16-4eee-9f7f-37d71012936c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Average Training Loss: 1.7066\n",
            "Average Validation Loss: 1.5454\n",
            "Average BLEU-1 Score: 0.2536190948494802\n",
            "Average BLEU-2 Score: 0.10411442307840107\n",
            "Average BLEU-3 Score: 0.03456727156773104\n",
            "Average BLEU-4 Score: 0.013980531827302778\n",
            "Average ROUGE-1 Score: 0.3085669224467127\n",
            "Average ROUGE-2 Score: 0.08623649680885356\n",
            "Average ROUGE-L Score: 0.28821198565003453\n",
            "Average METEOR Score: 0.0002143092647543686\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "\n",
        "# Calculate mean scores for all metrics\n",
        "mean_train_loss = np.mean(train_loss)\n",
        "mean_valid_loss = np.mean(valid_loss)\n",
        "mean_B1 = np.mean(B1)\n",
        "mean_B2 = np.mean(B2)\n",
        "mean_B3 = np.mean(B3)\n",
        "mean_B4 = np.mean(B4)\n",
        "mean_R1 = np.mean(R1)\n",
        "mean_R2 = np.mean(R2)\n",
        "mean_RL = np.mean(RL)\n",
        "mean_M = np.mean(M)\n",
        "\n",
        "# Print the results\n",
        "print(f\"Average Training Loss: {mean_train_loss:.4f}\")\n",
        "print(f\"Average Validation Loss: {mean_valid_loss:.4f}\")\n",
        "print(\"Average BLEU-1 Score:\", mean_B1)\n",
        "print(\"Average BLEU-2 Score:\", mean_B2)\n",
        "print(\"Average BLEU-3 Score:\", mean_B3)\n",
        "print(\"Average BLEU-4 Score:\", mean_B4)\n",
        "print(\"Average ROUGE-1 Score:\", mean_R1)\n",
        "print(\"Average ROUGE-2 Score:\", mean_R2)\n",
        "print(\"Average ROUGE-L Score:\", mean_RL)\n",
        "print(\"Average METEOR Score:\", mean_M)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 54,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "I25HJVDhGSdX",
        "outputId": "6b46174a-24c9-4659-b8b2-56d7f288977b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Saved evaluation metrics summary to 'evaluation_metrics_summary.csv'.\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Create a DataFrame from the averages\n",
        "df_metrics_summary = pd.DataFrame({\n",
        "    'Metric': ['Train Loss', 'Validation Loss', 'BLEU-1', 'BLEU-2', 'BLEU-3', 'BLEU-4', 'ROUGE-1', 'ROUGE-2', 'ROUGE-L', 'METEOR'],\n",
        "    'Average Score': [mean_train_loss, mean_valid_loss, mean_B1, mean_B2, mean_B3, mean_B4, mean_R1, mean_R2, mean_RL, mean_M]\n",
        "})\n",
        "\n",
        "# Save to CSV\n",
        "df_metrics_summary.to_csv('/content/drive/MyDrive/archive (4)/evaluation_metrics_summary.csv', index=False)\n",
        "print(\"Saved evaluation metrics summary to 'evaluation_metrics_summary.csv'.\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 96,
      "metadata": {
        "id": "qcPdfGzLb1uy"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "w5dia8blcDey"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "V100",
      "machine_shape": "hm",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.13"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
